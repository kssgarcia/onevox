# Onevox Configuration Example
# Copy this file to the appropriate location for your platform:
# - macOS: ~/Library/Application Support/com.onevox.onevox/config.toml
# - Linux: ~/.config/onevox/config.toml
# - Windows: %APPDATA%\onevox\config.toml

[daemon]
# Start daemon automatically on system boot
auto_start = true

# Logging level: trace, debug, info, warn, error
log_level = "debug"

# Log file rotation (in days)
log_retention_days = 7

[hotkey]
# Global hotkey combination (platform-specific defaults)
# macOS: "Cmd+Shift+0"
# Linux: "Ctrl+Shift+Space"
# Windows: "Ctrl+Shift+Space"
#
# Examples:
# - macOS: "Cmd+Shift+Space", "Ctrl+Option+D"
# - Linux: "Ctrl+Shift+Space", "Alt+D", "Super+Space"
# - Windows: "Win+Shift+Space", "Ctrl+Alt+D"
trigger = "Cmd+Shift+0"

# Mode: "push-to-talk" (hold to record) or "toggle" (press once to start, again to stop)
mode = "push-to-talk"

# Minimum hold duration (ms) to prevent accidental triggers
min_hold_duration_ms = 100

[audio]
# Audio input device (use "default" or specific device name)
# Run `onevox devices list` to see available devices
device = "HD 4.40BT"

# Sample rate (Hz) - models typically expect 16000
sample_rate = 16000

# Chunk duration for processing (ms)
# Smaller = lower latency, but more overhead
# Recommended: 100-200ms
chunk_duration_ms = 200

# Audio buffer size (seconds)
# How much audio to keep in memory before dropping
buffer_duration_sec = 2

[ui]
# Show floating desktop indicator while recording/processing
recording_overlay = true

[vad]
# Voice Activity Detection - automatically detect speech and silence
# 
# enabled = false: Manual control (recommended for Wayland/manual commands)
#   - Use start-dictation/stop-dictation commands to control recording
#   - Recording continues until you explicitly stop it
#
# enabled = true: Automatic speech detection (for hotkey-based workflows)
#   - Automatically stops recording after detecting silence
#   - Good for push-to-talk with hotkeys on X11/macOS
enabled = false

# VAD backend: "silero" (accurate, ONNX-based) or "webrtc" (fast, CPU-only)
backend = "energy"

# Detection threshold (0.0 - 1.0)
# Lower = more sensitive (may include noise)
# Higher = less sensitive (may cut off quiet speech)
threshold = 0.001

# Pre-roll: capture audio before VAD trigger (ms)
# Ensures you don't miss the beginning of speech
pre_roll_ms = 300

# Post-roll: continue recording after VAD silence (ms)
# Prevents cutting off the end of speech
post_roll_ms = 500

min_silence_chunks = 3
adaptive = true

[model]
# Model backend: "whisper_cpp" (native, recommended), "candle" (experimental)
backend = "whisper_cpp"

# Model identifier (without .bin extension)
# The model file should be in: ~/.cache/onevox/models/<model_id>/<model_id>.bin
# Download models with: onevox models download ggml-base.en
# Available models: ggml-tiny.en, ggml-base.en, ggml-small.en, ggml-medium.en, ggml-large-v3
model_path = "ggml-base.en"

# Compute device: "auto", "cpu", "gpu"
# "auto" will select GPU if available, otherwise CPU
device = "auto"

# Language code (ISO 639-1): "en", "es", "fr", "de", etc.
# Use "auto" for automatic detection (slower)
language = "en"

# Task: "transcribe" or "translate" (translate to English)
task = "transcribe"

# Load model at daemon startup (reduces first-transcription latency)
preload = true

[post_processing]
# Automatically add punctuation (experimental)
auto_punctuation = true

# Capitalize first letter of sentences
auto_capitalize = true

# Remove filler words (um, uh, like, etc.)
remove_filler_words = false

# Custom word replacements
# Format: "spoken" = "written"
[post_processing.replacements]
# "onevox" = "Onevox"
# "github" = "GitHub"
# "javascript" = "JavaScript"

[injection]
# Text injection method: "accessibility", "clipboard", "paste"
# - accessibility: Direct text injection (requires permissions)
# - clipboard: Copy to clipboard and simulate paste
# - paste: Simulate typing (slowest, but most compatible)
method = "accessibility"

# Delay before pasting (ms) - only for clipboard/paste methods
paste_delay_ms = 50

# Delay after closing overlay before injection starts (ms)
# Helps avoid focus races on some platforms/apps
focus_settle_ms = 80

# Simulate typing speed (chars/sec) - only for paste method
typing_speed = 100

[tui]
# Enable TUI (terminal user interface)
enabled = true

# Update frequency (Hz)
refresh_rate = 10

# Theme: "dark", "light"
theme = "dark"

[history]
# Enable transcription history tracking
enabled = true

# Maximum number of history entries to keep
# Oldest entries are automatically removed when limit is reached
max_entries = 1000

# Automatically save history after each transcription
# If false, history is only saved on daemon shutdown
auto_save = true

[telemetry]
# Enable performance metrics collection
enabled = true

# Metrics retention (days)
retention_days = 30

# Export format: "json", "csv", "prometheus"
export_format = "json"

[advanced]
# Maximum concurrent transcriptions
# Useful for batch processing, but increases memory usage
max_concurrent_transcriptions = 1

# Audio chunk queue size
# Larger = more buffer, but higher latency
chunk_queue_size = 10

# Model inference timeout (seconds)
inference_timeout_sec = 30

# Restart daemon on fatal errors
auto_restart = true
